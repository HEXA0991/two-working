{"cased": 0, "token_emb_dim": 100, "char_encoder": "lstm", "char_emb_dim": 30, "tag_emb_dim": 50, "hidden_dim": 200, "num_layers": 3, "max_depth": null, "crf": null, "loss_reduction": "sum", "dropout": 0.5, "lr": 0.001, "optimizer": "adam", "maxlen": 100, "vocab_size": 500000, "vocab_file": null, "ner_tag_vocab_size": 5, "re_tag_vocab_size": 3, "tag_form": "iob2", "device": "cuda:0", "lm_emb_dim": 4096, "lm_emb_path": "/home/Bio/zhangshiqi/codes/two-working/wv/lm.emb.ade0.pkl", "pos_emb_dim": 0, "head_emb_dim": 768, "warm_steps": 1000, "grad_period": 1}